# -*- coding: utf-8 -*-
"""Sentiment-analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wqrBdW_PiC7OzCW2nGhOVCPYC6jhYIN1

Eksplorasi dataset
"""

import pandas as pd

df = pd.read_csv ("twitter_training.csv")

print(df.columns)

print(df.head())

df.columns = ["id","username","sentiment","text"]

print(df["sentiment"].unique())

print(df["text"].unique())

#aku ubah sentiment nya menjadi angka
sentiment_mapping = {"Positive": 2, "Neutral": 1, "Negative": 0}
df["sentiment"] = df["sentiment"].map(sentiment_mapping)

"""Preprocessing data"""

import string
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

#pembersihan text sweet/ulasan

def clean_text(text):
    text = str(text).lower()
    text = text.translate(str.maketrans("", "", string.punctuation))
    return text

df["clean_text"] = df["text"].apply(clean_text)

label_encoder = LabelEncoder()
df["sentiment_encoded"] = label_encoder.fit_transform(df["sentiment"])

X = df["clean_text"]
y = df["sentiment_encoded"]

X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42, stratify=y)

# Cek jumlah data
print("Jumlah data training:", len(X_train))
print("Jumlah data testing:", len(X_test))
print("\nContoh data setelah preprocessing:")
print(df[["text", "clean_text", "sentiment", "sentiment_encoded"]].head())

"""Mengubah teks ke bentuk Numerik(TF-IDF)"""

from sklearn.feature_extraction.text import TfidfVectorizer

#inisialisasi
tfidf_vectorizer = TfidfVectorizer(max_features=5000)

#transformasi teks ke fitur numerik
X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)
X_test_tfidf = tfidf_vectorizer.transform(X_test)

#cek jumlah fitur yg dipilih TF-IDF
print("Jumlah fitur after TF-IDF :", X_train_tfidf.shape[1])

#kata-kata sering muncul
print("\nContoh kata-kata yang digunakan TF-IDF : ")
print(tfidf_vectorizer.get_feature_names_out()[:10])

"""dari output diatas '00','000' dan seterusnya. itu kata-kata yang sering muncul, dan kemungkinan besar mengandung banyak angka /kode numerik

untuk mengatasi nya yaitu hapus angka dari teks sebelum TF-IDF
"""

import re

def clean_text_v2(text):
  text = str(text).lower()
  text = re.sub(r"\d+", "", text)#hapus angka
  text = text.translate(str.maketrans("", "", string.punctuation))
  return text

df["clean_text"] = df["text"].apply(clean_text_v2)

#lanjut mengulangi proses TF-IDF

X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)
print(tfidf_vectorizer.get_feature_names_out()[:10])

print(df["clean_text"].head(10))

"""disini kita masih sama outputnya yaitu : '00', '000' dst. dengan menambahkan parameter tambahan token_pattern=r'\b[a-zA]{2,}Ì„b'"""

from sklearn.feature_extraction.text import TfidfVectorizer

# Inisialisasi ulang TF-IDF dengan filter untuk hanya mengambil kata (tanpa angka)
tfidf_vectorizer = TfidfVectorizer(max_features=5000, token_pattern=r'\b[a-zA-Z]{2,}\b')

# Transformasi ulang teks menjadi fitur numerik
X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)

# Cek kata-kata yang dipilih oleh TF-IDF setelah perbaikan
print(tfidf_vectorizer.get_feature_names_out()[:10])  # Lihat 10 kata pertama

tfidf_vectorizer = TfidfVectorizer(
    max_features=5000,
    token_pattern=r'\b[a-zA-Z]{3,}\b',
    stop_words="english"
)

# Transformasi ulang teks
X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)

# Cek hasil fitur TF-IDF setelah perbaikan
print(tfidf_vectorizer.get_feature_names_out()[:10])

from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS

# Tambahkan stopwords khusus
custom_stopwords = list(ENGLISH_STOP_WORDS) + ["aaa", "abilities", "ability", "absolute", "absolutely", "abt", "abuse"]

# TF-IDF dengan perbaikan
tfidf_vectorizer = TfidfVectorizer(
    max_features=5000,
    token_pattern=r'\b[a-zA-Z]{3,}\b',
    stop_words=custom_stopwords,  # Gunakan stopwords khusus
    min_df=5  # Hapus kata yang muncul kurang dari 5 kali
)

# Transformasi ulang teks
X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)

# Cek hasil fitur TF-IDF setelah perbaikan
print(tfidf_vectorizer.get_feature_names_out()[:10])

"""Melatih Model SVM untuk Klasifikasi Sentimen"""

from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report

# Inisialisasi model SVM
svm_model = SVC(kernel="linear", random_state=42)

# Latih model dengan data training
svm_model.fit(X_train_tfidf, y_train)

# Prediksi pada data uji
y_pred = svm_model.predict(X_test_tfidf)

# Evaluasi model
accuracy = accuracy_score(y_test, y_pred)
# Convert label_encoder.classes_ to a list of strings
target_names = [str(cls) for cls in label_encoder.classes_]
report = classification_report(y_test, y_pred, target_names=target_names)

# Output hasil
print(f"Akurasi Model: {accuracy}")
print("\nLaporan Klasifikasi:")
print(report)

"""Visualisasi Hasil dengan Confusion Matrix"""

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

# Buat Confusion Matrix
cm = confusion_matrix(y_test, y_pred)

# Plot Confusion Matrix
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix")
plt.show()

"""Menyimpan Model & TF-IDF Vectorizer"""

import joblib

# Simpan model SVM
joblib.dump(svm_model, "svm_sentiment_model.pkl")

# Simpan TF-IDF Vectorizer
joblib.dump(tfidf_vectorizer, "tfidf_vectorizer.pkl")

print("Model dan TF-IDF Vectorizer berhasil disimpan!")

!jupyter nbconvert --to script sentiment_analysis.ipynb

# Commented out IPython magic to ensure Python compatibility.
from google.colab import auth
auth.authenticate_user()

# Ganti dengan nama repository GitHub kamu
repository = "mrcahyono26proton/uas_sentimen_analysis"

# Konfigurasi Git
!git config --global user.email "mrcahyono26@proton.me"
!git config --global user.name "mrcahyono26proton"

# Tambahkan file ke GitHub
!git clone https://github.com/{repository}.git
# %cd uas_sentimen_analysis
!cp /content/svm_sentiment_model.pkl .
!cp /content/tfidf_vectorizer.pkl .
!git add .
!git commit -m "Upload trained model and vectorizer"
!git push origin main

!jupyter nbconvert --to script Sentiment-analysis.ipynb